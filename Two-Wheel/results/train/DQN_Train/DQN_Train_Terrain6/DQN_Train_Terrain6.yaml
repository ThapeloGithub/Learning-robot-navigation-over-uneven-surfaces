config_path: ./configs/main.yaml
environment:
  distance_to_goal_penalty: 0.7
  enable_keyboard: false
  environment_type: slope
  goal_step: 400
  goal_type: peak
  peak_position:
  - 1.15
  - 1.15
  - 0.3
  render_mode: DIRECT
  target_velocity_change: 0.5
  time_penalty: 0.2
  time_step_size: 1/20
  video_mode: false
  x_distance_to_goal: 40
epsilon_greedy:
  eps_decay: 0.0005
  eps_end: 0.05
  eps_init: 0.99
  epsilon_decay_type: exponential
  stretched_A: 0.5
  stretched_B: 0.1
  stretched_C: 0.1
gpu_id: '0'
hyperparameter_tuning:
  tuning_variable: learning_rate_actor
  type: model
  value_list:
  - 0.001
  - 0.0001
  - 1.0e-05
  - 1.0e-06
load_model_weights_path: ./results/train/dqn_train\DQN_Train_Terrain6\best_model.pt
mode: train
model:
  batch_size: 64
  dropout_rate:
  - 0
  - 0
  - 0
  gamma: 0.99
  hidden_layer_size:
  - 128
  - 128
  - 128
  learning_rate_actor: 0.0001
  learning_rate_critic: 0.0001
  name: DQN
  tau: 0.005
  weight_decay:
  - 0
  - 0
  - 0
plotting:
  plot_trajectories_episode_interval: 500
  record_trajectory_time_step_interval: 10
reward_function:
  end_goal_bonus: 1.0
  progress_reward: 0.1
  stability_penalty: 0.05
run:
  name: DQN_Train_Terrain6
testing:
  base_results_dir: ./results/test/
  device: auto
  max_steps_per_episode: 50000
  num_test_episodes: 1000
  num_workers: 40
  record_video: true
training:
  base_results_dir: ./results/train/dqn_train
  device: cpu
  max_steps_per_episode: 10000
  n_step: false
  num_train_episodes: 5000
  num_workers: 40
  save_model_weights: true
